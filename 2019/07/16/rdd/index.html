<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>[스파크2 프로그래밍] 2장_RDD - Always Learning</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Always Learning"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Always Learning"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="2.1 RDD이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해 2.1.1 들어가기에 앞서RDD 다루기 전에 알아야 할 것  스파크 클러스터클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.  분산데이터로서의 RDDRDD 는 회복력을 가진 분산 데"><meta property="og:type" content="blog"><meta property="og:title" content="[스파크2 프로그래밍] 2장_RDD"><meta property="og:url" content="https://junhee-ko.github.io/2019/07/16/rdd/"><meta property="og:site_name" content="Always Learning"><meta property="og:description" content="2.1 RDD이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해 2.1.1 들어가기에 앞서RDD 다루기 전에 알아야 할 것  스파크 클러스터클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.  분산데이터로서의 RDDRDD 는 회복력을 가진 분산 데"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://junhee-ko.github.io/img/og_image.png"><meta property="article:published_time" content="2019-07-15T15:00:00.000Z"><meta property="article:modified_time" content="2021-07-17T07:08:50.860Z"><meta property="article:author" content="junhee.ko"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://junhee-ko.github.io/2019/07/16/rdd/"},"headline":"[스파크2 프로그래밍] 2장_RDD","image":["https://junhee-ko.github.io/img/og_image.png"],"datePublished":"2019-07-15T15:00:00.000Z","dateModified":"2021-07-17T07:08:50.860Z","author":{"@type":"Person","name":"junhee.ko"},"publisher":{"@type":"Organization","name":"Always Learning","logo":{"@type":"ImageObject","url":"https://junhee-ko.github.io/img/logo.svg"}},"description":"2.1 RDD이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해 2.1.1 들어가기에 앞서RDD 다루기 전에 알아야 할 것  스파크 클러스터클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.  분산데이터로서의 RDDRDD 는 회복력을 가진 분산 데"}</script><link rel="canonical" href="https://junhee-ko.github.io/2019/07/16/rdd/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-15T15:00:00.000Z" title="7/16/2019, 12:00:00 AM">2019-07-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.860Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile">[스파크2 프로그래밍] 2장_RDD</h1><div class="content"><h3 id="2-1-RDD"><a href="#2-1-RDD" class="headerlink" title="2.1 RDD"></a>2.1 RDD</h3><p>이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해</p>
<h4 id="2-1-1-들어가기에-앞서"><a href="#2-1-1-들어가기에-앞서" class="headerlink" title="2.1.1 들어가기에 앞서"></a>2.1.1 들어가기에 앞서</h4><p>RDD 다루기 전에 알아야 할 것</p>
<ol>
<li><p>스파크 클러스터<br>클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.</p>
</li>
<li><p>분산데이터로서의 RDD<br>RDD 는 회복력을 가진 분산 데이터 집합입니다.</p>
</li>
<li><p>불변성<br>한번 만들어진 RDD 는 어떤 경우에도 변경되지 않습니다.</p>
</li>
<li><p>파티션<br>RDD 데이터는 클러스터를 구성하는 여러 서버에 나누어서 저장됩니다. 스파크는 분할된 데이터를 파티션이라는 단위로 관리합니다.</p>
</li>
<li><p>HDFS</p>
</li>
<li><p>Job 과 Executor<br>스파크 프로그램을 실행하는 것을 스파크 잡을 실행한다고 합니다. 하나의 잡은 클러스터에서 병렬로 처리되고, 각 서버마다 익스큐터라는 프로세스가 생성됩니다. 각자 할당된 파티션을 처리합니다.</p>
</li>
<li><p>드라이버 프로그램<br>드라이버란, 스파크 컨텍스트를 생성하고 그 인스턴스를 포함하는 있는 프로그램입니다.</p>
</li>
<li><p>트랜스포메이션과 액선<br>트랜스포메이션은 RDD 의 형태를 변형하는 연산입니다. 액선은 어떤 동작을 수행해 그 결과로서 RDD 가 아닌 다른 타입의 결과를 변환하는 연산입니다.</p>
</li>
<li><p>지연 동작과 최적화<br>트랜스포메이션 연산은 RDD 를 사용하는 다른 액션 연산이 호출될때까지는 실제 트랜스포메이션을 수행하지 않습니다. 따라서, 실행 계획의 최적화가 가능합니다. <strong>사용자가 입력한 변환 연산들을 즉시 수행하지 않고 모아뒀다가 한 번에 실행함으로써 불필요한 네티워크 통신 비용을 줄일 수 있습니다.</strong></p>
</li>
<li><p>함수의 전달</p>
</li>
</ol>
<h4 id="2-1-2-스파크-컨텍스트-생성"><a href="#2-1-2-스파크-컨텍스트-생성" class="headerlink" title="2.1.2 스파크 컨텍스트 생성"></a>2.1.2 스파크 컨텍스트 생성</h4><p>스파크컨텍스트는 <strong>스파크 애플리케이션과 클러스터의 연결을 관리하는 객체</strong>로서 스파크 애플리케이션은 반드시 스파크 컨텍스트를 생성해야합니다. 클러스터 마스터 정보와 애플리케이션 이름은 반드시 지정해야하는 필수정보입니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDDCreateSample&quot;</span>);</span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br></pre></td></tr></table></figure>

<h4 id="2-1-3-RDD-생성"><a href="#2-1-3-RDD-생성" class="headerlink" title="2.1.3 RDD 생성"></a>2.1.3 RDD 생성</h4><p>RDD 생성 방법 두가지가 있습니다.</p>
<ol>
<li><p>드라이버 프로그램의 컬렉션 객체 이용<br>컬렉션 객체는 자바나 파이썬의 경우에는 리스트 타입을 사용합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = sc.parallelize(Arrays.asList(<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>,<span class="string">&quot;d&quot;</span>,<span class="string">&quot;e&quot;</span>));</span><br></pre></td></tr></table></figure></li>
<li><p>파일과 같은 외부 데이터 이용<br>스파크는 내부적으로 하둡의 입력 및 출력 기능을 사용하므로 하둡이 다룰 수 있는 모든 입출력 유형을 다룰 수 있습니다.<br>파일의 각 줄은 한 개의 RDD 구성요소가 됩니다. 파일을 읽어들이는 과정은 하둡의 TextInputFormat 을 이용합니다. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = sc.textFile(<span class="string">&quot;&lt;spark_home_dir&gt;/README.md&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="2-1-4-RDD-기본-액션"><a href="#2-1-4-RDD-기본-액션" class="headerlink" title="2.1.4 RDD 기본 액션"></a>2.1.4 RDD 기본 액션</h4><h5 id="2-1-4-1-collect"><a href="#2-1-4-1-collect" class="headerlink" title="2.1.4.1 collect"></a>2.1.4.1 collect</h5><p>RDD 의 모든 원소를 모아서 배열로 돌려줍니다. 반환 타입이 RDD 가 아닌 배열이므로 이 연산은 액션에 속하는 연산입니다. RDD 에 있는 모든 요소들이 collect 연산을 호출한 서버의 메모리에 수집됩니다. 따라서 충분한 메모리 공간이 확보되어야합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>));</span><br><span class="line">List&lt;Integer&gt; result = rdd.collect();</span><br><span class="line"><span class="keyword">for</span> (Integer i : result) System.out.println(i);</span><br></pre></td></tr></table></figure>

<h5 id="2-1-4-2-count"><a href="#2-1-4-2-count" class="headerlink" title="2.1.4.2 count"></a>2.1.4.2 count</h5><p>RDD 구성하는 전체 요소 개수 반환합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>));</span><br><span class="line"><span class="keyword">long</span> result = rdd.count();</span><br><span class="line">System.out.println(result);</span><br></pre></td></tr></table></figure>

<h4 id="2-1-5-RDD-트랜스포메이션"><a href="#2-1-5-RDD-트랜스포메이션" class="headerlink" title="2.1.5 RDD 트랜스포메이션"></a>2.1.5 RDD 트랜스포메이션</h4><p><strong>기존 RDD 를 이용해 새로운 RDD 를 생성</strong>하는 연산입니다.</p>
<ul>
<li>Map 연산<ul>
<li>요소간의 mapping 을 정의한 함수를 RDD 에 속하는 모든 요소에 적용해 새로운 RDD 를 생성</li>
</ul>
</li>
<li>그룹화 연산<ul>
<li>특정 조건에 따라 요소를 그룹화 하거나 특정 함수를 적용</li>
</ul>
</li>
<li>집합 연산<ul>
<li>RDD 에 포함된 요소를 하나의 집합으로 간주할 때 서로 다른 RDD 간에 합집합, 교집합 등을 계산</li>
</ul>
</li>
<li>파티션 연산<ul>
<li>RDD 의 파티션 개수를 조정</li>
</ul>
</li>
<li>필터, 정렬 연산<ul>
<li>특정 조건을 만족하는 요소만 선택하거나 각 요소를 정해진 기준에 따라 정렬</li>
</ul>
</li>
</ul>
<h4 id="2-1-6-RDD-액션"><a href="#2-1-6-RDD-액션" class="headerlink" title="2.1.6 RDD 액션"></a>2.1.6 RDD 액션</h4><p>RDD 메서드 중에서 <strong>결과값이 정수나 리스트, 맵 등 RDD가 아닌 다른 타입</strong>인 것들입니다.<br>트렌스포메이션에 속하는 메서드는 느긋한 평가 방식을 사용합니다. 즉, 호출한다고 즉시 실행되는 것이 아니라 액션으로 분류되는 메서드가 호출되어야하만 비로소 실행됩니다. 액션 메서드를 호출하는 시점이 돼서야 비로소 그동안 쌓여있던 ~개의 트렌스포메이션 연산이 순차적으로 시작됩니다.<br><strong>주의할점은, 액션 메서드를 여러번 호출하면 트렌스포메이션 메서드도 여러번 실행됩니다.</strong> 예를 들어, rdd1 이라는 RDD 에 map() 연산을 적용해 rdd2 라는 RDD 를 만들었다고 할때, rdd2 의 액션 메서드를 두번 호출하면 map() 연산도 두번 실행됩니다. 따라서, 반복 수행 성능을 개선하기 위해 캐쉬를 적절히 사용하고, 코드 작성시 반복 수행 가능성을 염두해야합니다.</p>
<h4 id="2-1-7-RDD-데이터-불러오기와-저장하기"><a href="#2-1-7-RDD-데이터-불러오기와-저장하기" class="headerlink" title="2.1.7 RDD 데이터 불러오기와 저장하기"></a>2.1.7 RDD 데이터 불러오기와 저장하기</h4><p>스파크는 하둡 API 를 기반으로 다양한 데이터 포맷과 파일 시스템을 지원합니다.</p>
<ul>
<li>파일 포맷<ul>
<li>텍스트 파일 / JSON / 하둡의 시퀀스 파일 / csv …</li>
</ul>
</li>
<li>파일 시스템<ul>
<li>로컬 파일 시스템 / HDFS / AWS 의 S3 / 오픈스택의 Swift …</li>
</ul>
</li>
</ul>
<h5 id="2-1-7-1-텍스트-파일"><a href="#2-1-7-1-텍스트-파일" class="headerlink" title="2.1.7.1 텍스트 파일"></a>2.1.7.1 텍스트 파일</h5><p>스파크는 다양한종류의 파일 시스템을 다룰수 있기 때문에 파일의 경로를 지정하는 방법도 파일 시스템의 종류에 따라 다릅니다.</p>
<ul>
<li>로컬파일 시스템<ul>
<li>file:///path</li>
</ul>
</li>
<li>HDFS<ul>
<li>hdfs://master:prot/path/..</li>
</ul>
</li>
<li>S3<ul>
<li>S3n://bucket/path</li>
</ul>
</li>
</ul>
<p><strong>주의할점은, 스파크가 클러스터를 이루는 다수의 서버 상에서 동작하기 때문에,  위에서 지정한 경로는 클러스터를 구성하는모든 서버에서 동일하게 접근 가능해야합니다.</strong> 따라서, 로컬 파일 시스템의경로를 데이터 위치로 지정하면 클러스터를 구성하는 모든 서버에서 “file:///data/sample.txt” 라는 경로를 통해 지정한 파일로 접근할 수 있어야합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JavaRdd&lt;Integer&gt; rdd = sc.parallelize(fillToN(<span class="number">1000</span>),  <span class="number">3</span>); <span class="comment">// 0~1000 까지의 숫자로 구성, 3개 파티션</span></span><br><span class="line">Class codec =. org.apache.hadoop.io.compress.GzipCodec.class;</span><br><span class="line"></span><br><span class="line"><span class="comment">// save</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">&quot;&lt;path_to_save&gt;/sub1&quot;</span>);</span><br><span class="line">rdd.saveAsTextFile(<span class="string">&quot;&lt;path_to_save&gt;/sub2&quot;</span>,  codec);</span><br><span class="line"></span><br><span class="line"><span class="comment">// load</span></span><br><span class="line">JavaRDD&lt;String&gt; rdd2 = sc.textFile(<span class="string">&quot;&lt;path_to_save&gt;/sub1&quot;</span>);</span><br></pre></td></tr></table></figure>

<h5 id="2-1-7-2-Object-File"><a href="#2-1-7-2-Object-File" class="headerlink" title="2.1.7.2 Object File"></a>2.1.7.2 Object File</h5><p>텍스트 파일을 사용하는 것과. 크게 다르지 않습니다. 다만, RDD 에 포함된 데이터를 오프젝트 파일로 다루기 위해서는 각 요소(오브젝트) 가 자바의 Serializable 인터페이스를 구현하고 있어야합니다. 그리고, 저장된 RDD 의 타입이 RDD[Int]  였다면, 이 파일으 읽어서 생성한 RDD 도 동일한 RDD[Int] 타입입니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">JavaRdd&lt;Integer&gt; rdd = sc.parallelize(fillToN(<span class="number">1000</span>),  <span class="number">3</span>); <span class="comment">// 0~1000 까지의 숫자로 구성, 3 개 파티션</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// save</span></span><br><span class="line">rdd.saveAsObjectFile(<span class="string">&quot;&lt;path_to_save&gt;/sub_path&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// load</span></span><br><span class="line">JavaRDD&lt;Integer&gt; rdd2 = sc.objectFile(<span class="string">&quot;&lt;path_to_save&gt;/sub_path&quot;</span>);</span><br><span class="line">System.out.println(rdd2.take(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>

<h5 id="2-1-7-3-시퀀스-파일"><a href="#2-1-7-3-시퀀스-파일" class="headerlink" title="2.1.7.3 시퀀스 파일"></a>2.1.7.3 시퀀스 파일</h5><p>키와 값으로 구성된 데이터를 저장하는 이진 파일 포맷입니다. 하둡에서 자주 사용되는 대표적인 파일 포맷입니다. 시퀀스 파일로다루고자 하는 RDD의 데이터는 하둡의 Wriable 인터페이스를 구현하고 있어야합니다.</p>
<h4 id="2-1-8-클러스터-환경에서의-공유-변수"><a href="#2-1-8-클러스터-환경에서의-공유-변수" class="headerlink" title="2.1.8 클러스터 환경에서의 공유 변수"></a>2.1.8 클러스터 환경에서의 공유 변수</h4><p>하둡이나 스파크와 같이 클러스터 환경에서 동작하는 애플리케이션은 하나의 잡을 수행하기 위해 클러스터에 속한 다수의 서버에서 여러 개의 프로세스를 실행하므로 모든 프로세스가 공유할 수 있는 자원을 관리하기 쉽지 않습니다. <strong>이러한 프레임워크는 다수의 프로세스가 공유할 수 있는 읽기 자원과 쓰기 자원을 설정할 수 있도록 지원합니다.</strong></p>
<ul>
<li>하둡<ul>
<li>분산캐시 / 카운터</li>
</ul>
</li>
<li>스파크<ul>
<li>브로드캐스트 변수 / 어큐뮬레이텨</li>
</ul>
</li>
</ul>
<ol>
<li>브로드캐스트 변수<br>스파크 잡이 실행되는 동안 클러스터 내의 모든 서버에서 공유할 수 있는 읽기 전용 자원을 설정할 수 있는 변수입니다.<ul>
<li>먼저 공유하고자 하는 데이터를 포함하는 오브젝트를 생성</li>
</ul>
</li>
</ol>
<ul>
<li>이 오브젝트를 스파크컨텍스트의 broadcast() 메서드의 인자로 지정해 해당 메서드를 실행<ul>
<li>이렇게 생성된 브로드캐스트 변수를 사용할때는 생성한 브로드캐스트 변수의 value() 메서드를 통해 접근<br>클러스터 간에 공유할 변수가 있다고 해서 무조건 브로드캐스트 변수를 사용해야하는 것은 아닙니다. <strong>액션 연산을 수행할때 동일한 스테이지 내에서 실행되는 태스크 간에는 필요한 변수를 자동으로 브로드캐스트 변수를 이용해서 전달</strong>하기 때문에 명시적으로 브로드 캐스트 변수를 지정하지않아도 됩니다. </li>
</ul>
</li>
</ul>
<ol start="2">
<li>어큐뮬레이터<br>쓰기 동작을 위한것입니다. 클러스터 내의 모든 서버가 공유하는 쓰기 공간을 제공함으로써 <strong>각 서버에서 발생하는 특정 이벤트의 수를 세거나 관찰하고 싶은 정보를 모아두는 용도로 활용할 수 있습니다.</strong><br>어큐뮬레이터를 생성하려면 org.apache.spark.util.AccumulatorV2 클래스를 상속받은 클래스를 정의하고, 이 클래스의 인스턴스를 생성합니다. 그리고 생성한 어큐뮬레이터 인스턴스를 스파크컨텍스트가 제공하는 register() method 를 이용해 등록합니다.<br>어큐뮬레이터를 사용할 때는 두 가지를 기억해야합니다.<br>첫 째, 어큐뮬레이터를 증가시키는 동작은 클러스터의 모든 데이터 처리 프로세스에서 가능하지만 데이터를 읽는 동작은 드라이버 프로그램 내에서만 가능합니다. 즉, RDD 의 트랜스포메이션이나 액션 연산 내부에는 어큐뮬레이터의 값을 증가시킬뿐 그 값을 참조해서 사용하는 것은 불가능합니다.<br>둘 째, 일부러 의도한 특별한 목적이없는 한 어큐뮬레이터는 액션 연산을 수행하는 메서드에서만 사용해야합니다. 왜냐하면 트렌스포매이션 연산은 액션 연산과 달리 하나의 잡 내에서 필요에 따라 수차례 반복 실행될 수 있기 때문입니다. 따라서 map(), flatmap() 과 같은 트랜스포메이션 연산 내용에 어큐뮬레이터의 값을 증가시키는 코드가 포함될 경우 정확하지 않은 데이터가 집계 될 수 있습니다.</li>
</ol>
</div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/08/07/spark-sql/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">[스파크2 프로그래밍] 5장_스파크SQL 과 데이터프레임,데이터셋</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/07/01/spark-config/"><span class="level-item">[스파크2 프로그래밍] 4장_스파크 설정</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://junhee-ko.github.io/2019/07/16/rdd/';
            this.page.identifier = '2019/07/16/rdd/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'junheeko' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><p class="title is-size-4 is-block" style="line-height:inherit;">Junhee Ko</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">308</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">16</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/junhee-ko" target="_blank" rel="noopener">Follow</a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-24T15:00:00.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/spring-data-jpa-crud/">Spring Data JPA CRUD</a></p><p class="categories"><a href="/categories/jpa/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-21T15:00:00.000Z">2021-04-22</time></p><p class="title"><a href="/2021/04/22/ack-mode-batch/">Spring Kafka Listener Container BATCH AckMode</a></p><p class="categories"><a href="/categories/kafka/">Kafka</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-20T15:00:00.000Z">2021-04-21</time></p><p class="title"><a href="/2021/04/21/cmak/">CMAK</a></p><p class="categories"><a href="/categories/kafka/">Kafka</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-16T15:00:00.000Z">2021-04-17</time></p><p class="title"><a href="/2021/04/17/proxy-pattern/">Proxy Pattern</a></p><p class="categories"><a href="/categories/java/">Java</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-28T15:00:00.000Z">2021-01-29</time></p><p class="title"><a href="/2021/01/29/oauth-refresh-token/">[OAuth 2.0 마스터] 8장_엑세스 토큰 갱신하기</a></p><p class="categories"><a href="/categories/oauth/">OAuth</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">180</span></span></a></li><li><a class="level is-mobile" href="/categories/big-data/"><span class="level-start"><span class="level-item">Big Data</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/container/"><span class="level-start"><span class="level-item">Container</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/jpa/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/kafka/"><span class="level-start"><span class="level-item">Kafka</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/oauth/"><span class="level-start"><span class="level-item">OAuth</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/oop/"><span class="level-start"><span class="level-item">OOP</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/os/"><span class="level-start"><span class="level-item">OS</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/redis/"><span class="level-start"><span class="level-item">Redis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/tdd/"><span class="level-start"><span class="level-item">TDD</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/test-code/"><span class="level-start"><span class="level-item">Test Code</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/grpc/"><span class="level-start"><span class="level-item">gRPC</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a><p class="is-size-7"><span>&copy; 2021 junhee.ko</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>