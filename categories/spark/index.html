<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: Spark - Always Learning</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Always Learning"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Always Learning"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Always Learning"><meta property="og:url" content="https://junhee-ko.github.io/"><meta property="og:site_name" content="Always Learning"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://junhee-ko.github.io/img/og_image.png"><meta property="article:author" content="junhee.ko"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://junhee-ko.github.io"},"headline":"Always Learning","image":["https://junhee-ko.github.io/img/og_image.png"],"author":{"@type":"Person","name":"junhee.ko"},"publisher":{"@type":"Organization","name":"Always Learning","logo":{"@type":"ImageObject","url":"https://junhee-ko.github.io/img/logo.svg"}},"description":null}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Spark</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-08-06T15:00:00.000Z" title="8/7/2019, 12:00:00 AM">2019-08-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.821Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/08/07/spark-sql/">[스파크2 프로그래밍] 5장_스파크SQL 과 데이터프레임,데이터셋</a></h1><div class="content"><p>RDD 의 장점은, </p>
<ul>
<li>분산환경에서 메모리 기반으로 빠르고 안정적으로 동작하는 프로그램을 만들 수 있다는 것과, </li>
<li>RDD 가 제공하는 풍부한 데이터 처리 연산입니다. ( &lt;-&gt; 맵과 리듀스로만 문제를 해결 ) </li>
</ul>
<p>RDD 의 단점은,</p>
<ul>
<li>스키마를 표현할 수 없다는 것입니다. </li>
</ul>
<p>스파크 SQL 은 RDD 의 이 단점을 보완할 수 있도록 또 다른 유형의 데이터 모델과 API를 제공하는 스파크 모듈입니다. 스파크 SQL 에서 데이터를 다루는 방법은 SQL을 사용하는 것과 데이터셋 API 를 사용하는 방법이 있습니다.<br>데이터셋은 스파크 1.6 버젼에서 처음 소개된 것으로 자바와 스칼라 언어에서만 사용할 수 있었고, 그 이전에는 데이터프레임이라는 클래스를 구현 언어와 상관없이 사용하고 있었습니다. <strong>스파크 2.0 부터 데이터프레임 클래스가 데이터셋 클래스로 통합</strong>되면서 Type Alias 라는 독특한 기능을 가진 스칼라 언어에서만 기존과 같은 데이터 프레임을 사용할 수 있고 해당 기능이 없는 자바에서는 데이터셋 클래스만을 사용할 수 있게 됐습니다.<br>스칼라의 데이터프레임은 “type DataFrame = Dataset[Row]” 와 같이 정의돼 있는데 바로 이 구문이 Type Alias 에 해당하는 부분으로, <strong>Dataset 의 타입 파라미터가 Row 인 경우를 DataFrame</strong> 이라는 이름으로도 사용하겠다는 의미입니다.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> ds = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>).toDS</span><br><span class="line">ds.show</span><br><span class="line">ds.printScheme</span><br></pre></td></tr></table></figure>

<h3 id="5-1-데이터셋"><a href="#5-1-데이터셋" class="headerlink" title="5.1 데이터셋"></a>5.1 데이터셋</h3><p>데이터셋 이전에는 데이터프레임이라는 API 를 사용했습니다. 가장 큰 특징은, 기존 RDD 와는 다른 형태를 가진 <strong>SQL 과 유사한 방식의 연산을 제공</strong>했다는 점입니다. 예를 들어,</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.map(v=&gt;v+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>와 같은 map() 연산을 사용한 것에 반해, 동일한 요소로 구성된 데이터프레임에서는 </p></div><a class="article-more button is-small is-size-7" href="/2019/08/07/spark-sql/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-15T15:00:00.000Z" title="7/16/2019, 12:00:00 AM">2019-07-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.860Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/07/16/rdd/">[스파크2 프로그래밍] 2장_RDD</a></h1><div class="content"><h3 id="2-1-RDD"><a href="#2-1-RDD" class="headerlink" title="2.1 RDD"></a>2.1 RDD</h3><p>이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해</p>
<h4 id="2-1-1-들어가기에-앞서"><a href="#2-1-1-들어가기에-앞서" class="headerlink" title="2.1.1 들어가기에 앞서"></a>2.1.1 들어가기에 앞서</h4><p>RDD 다루기 전에 알아야 할 것</p>
<ol>
<li><p>스파크 클러스터<br>클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.</p>
</li>
<li><p>분산데이터로서의 RDD<br>RDD 는 회복력을 가진 분산 데이터 집합입니다.</p>
</li>
<li><p>불변성<br>한번 만들어진 RDD 는 어떤 경우에도 변경되지 않습니다.</p>
</li>
<li><p>파티션<br>RDD 데이터는 클러스터를 구성하는 여러 서버에 나누어서 저장됩니다. 스파크는 분할된 데이터를 파티션이라는 단위로 관리합니다.</p>
</li>
<li><p>HDFS</p>
</li>
<li><p>Job 과 Executor<br>스파크 프로그램을 실행하는 것을 스파크 잡을 실행한다고 합니다. 하나의 잡은 클러스터에서 병렬로 처리되고, 각 서버마다 익스큐터라는 프로세스가 생성됩니다. 각자 할당된 파티션을 처리합니다.</p>
</li>
<li><p>드라이버 프로그램<br>드라이버란, 스파크 컨텍스트를 생성하고 그 인스턴스를 포함하는 있는 프로그램입니다.</p>
</li>
<li><p>트랜스포메이션과 액선<br>트랜스포메이션은 RDD 의 형태를 변형하는 연산입니다. 액선은 어떤 동작을 수행해 그 결과로서 RDD 가 아닌 다른 타입의 결과를 변환하는 연산입니다.</p>
</li>
<li><p>지연 동작과 최적화<br>트랜스포메이션 연산은 RDD 를 사용하는 다른 액션 연산이 호출될때까지는 실제 트랜스포메이션을 수행하지 않습니다. 따라서, 실행 계획의 최적화가 가능합니다. <strong>사용자가 입력한 변환 연산들을 즉시 수행하지 않고 모아뒀다가 한 번에 실행함으로써 불필요한 네티워크 통신 비용을 줄일 수 있습니다.</strong></p>
</li>
<li><p>함수의 전달</p>
</li>
</ol>
<h4 id="2-1-2-스파크-컨텍스트-생성"><a href="#2-1-2-스파크-컨텍스트-생성" class="headerlink" title="2.1.2 스파크 컨텍스트 생성"></a>2.1.2 스파크 컨텍스트 생성</h4><p>스파크컨텍스트는 <strong>스파크 애플리케이션과 클러스터의 연결을 관리하는 객체</strong>로서 스파크 애플리케이션은 반드시 스파크 컨텍스트를 생성해야합니다. 클러스터 마스터 정보와 애플리케이션 이름은 반드시 지정해야하는 필수정보입니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;RDDCreateSample&quot;</span>);</span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br></pre></td></tr></table></figure>

<h4 id="2-1-3-RDD-생성"><a href="#2-1-3-RDD-생성" class="headerlink" title="2.1.3 RDD 생성"></a>2.1.3 RDD 생성</h4><p>RDD 생성 방법 두가지가 있습니다.</p></div><a class="article-more button is-small is-size-7" href="/2019/07/16/rdd/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-30T15:00:00.000Z" title="7/1/2019, 12:00:00 AM">2019-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.869Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/07/01/spark-config/">[스파크2 프로그래밍] 4장_스파크 설정</a></h1><div class="content"><ul>
<li>애플리캐이션 단위로 설정<ul>
<li>Spark Properties 사용</li>
</ul>
</li>
<li>각 서버 단위로 설정<ul>
<li>서버의 환경 변수를 이용해 등록</li>
</ul>
</li>
</ul>
<h3 id="4-1-스파크-프로퍼티"><a href="#4-1-스파크-프로퍼티" class="headerlink" title="4.1 스파크 프로퍼티"></a>4.1 스파크 프로퍼티</h3><p>스파크 프로퍼티는 개별 애플리캐이션 실행관 관련된 설정값을 정의하는 곳입니다. 스파크 컨텍스트를 생성할 때 사용했던 SparkConf 인스턴스나 자바 시스템 프로퍼티를 이용해 등록 가능합니다.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkCont</span>().setAppName(<span class="string">&quot;myApp&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br></pre></td></tr></table></figure>

<p>SparkConf 클래스는 스파크 애플리캐이션 실행관 관련된 다양한 설정 정보를 키와 값 형태로 등록할수 있는 함수(set / get) 을 제공합니다. 애플리캐이션 이름과 같이 반드시 지정해야 하는 주요 속성에 대해서는 setMaster, setAppName 과 같은 별도의 메서드를 제공합니다.<br>SparkConf 를 이용하는 것의 문제점은 애플리캐이션의 비즈니스 로직과는 직접 관련이 없는 익스큐터의 메모리 설정이나 코어 수 할당관 관련된 부분이 항상 프로그램 코드에 포함돼 있어야 한다는 것입니다. 그래서, 프로그램이 실행되는 시점에 동적으로 필요한 설정값을 설정할수 있는 두 가지 방법이 있습니다.</p>
<ol>
<li><p>spark-shell / spar-submit<br>스크립트 실행시 사전에 지정된 형식에 따라 명령행 옵션을 이용해 원하는 설정값을 지정합니다.</p>
</li>
<li><p>설정 정보가 담긴 파일 사용<br>스파크 홈의 conf 디렉터리 아래에 spark-defaults.conf 파일을 만들고 이 파일에 설정 정보를 등록해 두면 스파크 쉘이나 sprak-submit 스크립트가 해당 파일의 내용을 읽습니다. </p>
</li>
</ol>
<h3 id="4-2-환경변수"><a href="#4-2-환경변수" class="headerlink" title="4.2 환경변수"></a>4.2 환경변수</h3><p>각 서버 단위로 적용돼야 하는 환경 정보는 각 서버의 환경 변수를 이용해 등록할 수 있습니다. 예를 들어, 자바의 설치 경로와 같은 정보가 서버별로 다르게 설정돼 있다면 환경변수를 이용해 해당 서버의정보를 변경할 수 있습니다. 환경 변수 ex )</p>
<ul>
<li>JAVA_HOME : 자바 설치 경로</li>
<li>SPARK_LOCAL_IP : 사용할 IP</li>
<li>SPARK_PUBLIC_DNS : 애플리케이션 호스트명</li>
<li>SPARK_CONF_DIR : spar-defaults.conf / spark-env.sh / log4j.properties 파일 등 설정 파일이 놓인 디렉토리 위치</li>
</ul>
<p>일부 환경 변수는 사용하는 클러스터 매니저의 종류에 따라 설정 방법이 다릅니다.</p></div><a class="article-more button is-small is-size-7" href="/2019/07/01/spark-config/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-30T15:00:00.000Z" title="7/1/2019, 12:00:00 AM">2019-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.870Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/07/01/spark-cluster/">[스파크2 프로그래밍] 3장_클러스터 환경</a></h1><div class="content"><h3 id="3-1-클러스터-환경"><a href="#3-1-클러스터-환경" class="headerlink" title="3.1 클러스터 환경"></a>3.1 클러스터 환경</h3><p>이번 장의 목표 : 분산 처리를 위한 시스템 아키텍처와, 그와 관련된 다양한 설정 및 매개변수를 이해하는 것.<br>스파크에서는 클러스터 자원을 관리해주는 역할을 하는 컴포넌트 클래스를 클러스터 매니저라고 합니다. 2.3.0 버젼에서는 네 종류의 클러스터 매니저가 사용되고 있습니다.</p>
<h4 id="3-1-1-클러스터-모드와-컴포넌트"><a href="#3-1-1-클러스터-모드와-컴포넌트" class="headerlink" title="3.1.1 클러스터 모드와 컴포넌트"></a>3.1.1 클러스터 모드와 컴포넌트</h4><p>스파크 클러스터는 <strong>드라이버 / 클러스터 매니저 / 익스큐터 / 워커 노드</strong>의 조합.<br>클러스터란, 여러 대의 서버가 네트워크를 통해 연결되어 마치 하나의 서버인 것처럼 동작하는 방식을 의미합니다. 전체 서버의 자원과 동작을 세밀하고 효율적으로 제어할 수 있는 별도 모듈을 클러스터 매니저라고 부릅니다.<br>스파크에서는  추상화된 클러스터 모델을 제공함으로써 사용하는 클러스터의 종류에 상관없이 일관된 방법으로 프로그램을 작성하고 클러스터를 관리할 수 있게 지원하고 있습니다.<br>“스파크 애플리케이션을 실행했다” 라고 하는 말은, 드라이버 프로그램에 있는 메인 함수를 실행해 스파크컨텍스트를 생성하고, 이를 이용해 각 워커 노드에 익스큐터 프로세스를 구동시켜 작업을 수행했다라는 뜻입니다. 즉, 익스큐터 하나가 사용할 자원(CPU 나 메모리) 을 정한뒤, 작업 실행 요청이 발생할 때마다 필요한 수만큼의 익스큐터를 할당하는 방식으로 자원을 할당합니다.<br>사용가능한 스파크컨텍스트가 준비돼 있다는 것은 클러스터 메니저와의 연동을 포함해서, 스파크 애플리케이션이 동작하는 데 필요한 다수의 서비스가 준비돼 있다는 의미이며, 이렇게 생성된 스파크컨텍스트를 이용해 RDD 나 브로드캐스트 또는 어큐뮬레이터 변수를 생성하고 사용할수 있음을 의미하는 것입니다.<br>쇼핑몰 방문자의 방문 로그를 분석하는 작업을 한다고 가정하고 작업을 수행하는 절차를 보겠습니다.</p>
<ol>
<li>드라이버 프로그램이 포함된 애플리케이션 코드를 작성</li>
<li>코드를 빌드하고 jar 나 zip 파일 등으로 패키징</li>
<li>생선한 패키지 파일을 스파크에서 제공하는 spark-submit 셸을 이용해 클러스터에 배포하고 실행</li>
<li>스파크 애플리케이션의 드라이버 프로그램이 실행되면 스파크컨텍스트가 생성되면서 클러스터 매니저와 연동되어 각 클러스터 서버에 작업을 처리하기 위한 프로세스를 생성. 이때 작업에 필요한 서버를 워커노드라고 하며, 각 워커노드에 생성된 프로세스를 익스큐터.</li>
<li>익스큐터가 생성되면 드라이버 프로그램은 작성된 프로그램에 의해 트렌스포메이션과 액션을 수행. 트렌스포메이션 연산이 호출할 때는 실제 작업을 수행하지 않고 액션 여산이 호출될 때만 실제 작업을 수행하느데, 이 작업 단위를 Job. 즉, 잡은 액션 연산의 수만큼 생성.</li>
<li>생성된 잡은 실제로 수행될 때 스테이지라는 단계로 나누어 실행. 스테이지를 나누는 기준이 되는 것은 데이터 셔플 필요 여부. 즉, 각 서버에 있는 데이터를 네트워크를 통해 다른 서버로 재배치해야 하는지 여부. 셔플이 발생하면 네트워크를 통해 대량의 데이터를 정렬하고 전송하는 등의 부하가 발생해 전체 작업 성능에 좋지 않은 영향을 끼치기 때문. 따라서, 데이터를 이동하지 않는 상태에서 처리할 수 있는 연산을 최대한 같은 스테이지로 묶어 처리하면 셔플 발생을 최소화.</li>
<li>각 스테이지는 여러 개의 태스크로 나눠진 후 분산처리를 위해 여러 익스큐터에 할당되며, 이 태스크가 실제 익스큐터에 전달되는 작업의 단위. 이 때, 익스큐터는 두 가지 역할 수행. 하나는 할당받은 테스크를 처리. 다른 하나는 이미 처리된 데이터를 나중에 빠르게 재사용할 수 있게 메모리에 저장.</li>
</ol>
<h4 id="3-1-2-클러스터-모드를-위한-시스템-구성"><a href="#3-1-2-클러스터-모드를-위한-시스템-구성" class="headerlink" title="3.1.2 클러스터 모드를 위한 시스템 구성"></a>3.1.2 클러스터 모드를 위한 시스템 구성</h4><p>일반적으로, 별도의 서버에 애플리케이션을 배포한 뒤 해당 서버에서 드라이버 프로그램을 구동하고 실제 데이터 처리는 스파크 클러스터에서 수행되게 하는 방법을 사용합니다. 이렇게, <strong>클러스터에 작업을 요청하는 서버를 배치 서버 또는 클라이언트 서버라고 부릅니다.</strong><br>다음은 클러스터 구성에 필요한 서버의 종류입니다.</p>
<ol>
<li>로컬 개발 서버</li>
<li>애플리케이션 실행 서버<br>spark-submit, spark-shell 등의 스크립트를 이용해 스파크 어플리케이션을 맨 처음 실행하는 서버.</li>
<li>클러스터 서버<br>클러스터 구성에 참여하는 서버. 클러스터 운영을 위한 마스터 서버의 역할을 수행하거나, 실제 데이터를 처리하고 필요에 따라 저장하는 워커 노드의 역할을 수행하는 서버입니다. </li>
</ol>
<h4 id="3-1-3-드라이버-프로그램과-디플로이-모드"><a href="#3-1-3-드라이버-프로그램과-디플로이-모드" class="headerlink" title="3.1.3 드라이버 프로그램과 디플로이 모드"></a>3.1.3 드라이버 프로그램과 디플로이 모드</h4><p>모든 스파크 어플리케이션에는 스파크컨텍스트를 생성하는 코드가 포함돼 있는데, 이 부분이 포함된 프로그램을 가리켜 드라이버 프로그램이라고 합니다. 클러스터에서 실행할 때는 클러스터 매니저에게 애플리케이션 실행을 요청합니다. (“제출한다” 라고 합니다.)<br>작업 요청을 받은 클러스터 매니저는 필요한 자원을 할당하고 작업을 수행하는데, 클러스터 매니저마다 다른 형태로 애플리케이션을 실행시킬 수 있습니다. 이처럼 서로 다른 실행 모드를 ‘디플로이 모드’ 라고 합니다. ‘클라이언트 디플로이 모드’ 와 ‘클러스터 디플로이 모드’ 가 있습니다.<br><strong>클라이언트 디플로이 모드란, 애플리케이션을 실행한 프로세스 내부에서 드라이버 프로그램을 구동하는 것</strong>으로, 드라이버 프로그램은 작업을 요청한 클라이언트 서버 프로세스에 포함되어 실행됩니다. 따라서 스파크 어플리케이션을 실행했던 콘솔을 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시키면 스파크컨텍스트도 함께 종료되면서 수행 중이던 모든 스파크 잡이 중지 됩니다.<br><strong>클러스터 디폴로이 모드란, 애플리케이션을 실행한 프로세스는 클러스터 매니저에게 작업 실행만 요청하고 즉시 종료되며, 실제 드라이버 프로그램의 실행은 클러스터 내부에서 실행되는 것</strong>을 의미합니다. 클러스터 매니저에게 잡이 전달되고 최초 어플리케이션을 실행했던 콘솔들 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시켜도 전체 스파크 어플리케이션의 동작에는 영향을 끼치지 않습니다.</p></div><a class="article-more button is-small is-size-7" href="/2019/07/01/spark-cluster/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-06-22T15:00:00.000Z" title="6/23/2019, 12:00:00 AM">2019-06-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-17T07:08:50.810Z" title="7/17/2021, 4:08:50 PM">2021-07-17</time></span><span class="level-item"><a class="link-muted" href="/categories/spark/">Spark</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/06/23/spark-intro/">[스파크2 프로그래밍] 1장_스파크 소개</a></h1><div class="content"><h3 id="1-1-스파크"><a href="#1-1-스파크" class="headerlink" title="1.1 스파크"></a>1.1 스파크</h3><h4 id="1-1-2-빅데이터의-정의"><a href="#1-1-2-빅데이터의-정의" class="headerlink" title="1.1.2 빅데이터의 정의"></a>1.1.2 빅데이터의 정의</h4><p>“다앙햔 형태를 지닌 대량의 데이터가 빠른 속도로 쌓이고 있다면 이를 빅데이터라고 부를 수 있다”<br>빅데이터의 중요한 특성 세 가지는 크기, 속도, 댜양성입니다.</p>
<ul>
<li>크기 : 대량의 데이터를 처리</li>
<li>속도 : 데이터의 증가가 지속적이고 빠르기 때문에 이에 부합하는 빠른 데이터 처리 기술이 필요</li>
<li>다양성 : 빅데이터의 다양성</li>
</ul>
<h4 id="1-1-3-빅데이터-솔루션"><a href="#1-1-3-빅데이터-솔루션" class="headerlink" title="1.1.3 빅데이터 솔루션"></a>1.1.3 빅데이터 솔루션</h4><p>먼저 빅데이터를 처리하는 플랫폼이니만큼 데이터를 가져오는 데이터 수집 모듈이 필요합니다. 다음으로는, 이렇게 수집된 데이터를 저장하고 조회하는 저장 및 조회 모듈이 필요합니다. 다음으로, 데이터를 분석하고 그 결과를 가공할 수 있는 모듈이 필요합니다. 그리고, 이제 이 모든 과정을 제어할 수 있는 워크플로우 엔진이 필요할 수도 있습니다. </p>
<ul>
<li>데이터 수집 : 플럼 / 카프카 / 스쿱</li>
<li>데이터 저장 및 처리 : 하둡 / HBase / 카산드라 / 레디스 / 피그 / 하이브 / 스파크</li>
<li>데이터 분석 및 기타 소프트웨어 : R / 클라우데라 / 엘라스틱서치</li>
</ul>
<h4 id="1-1-4-스파크"><a href="#1-1-4-스파크" class="headerlink" title="1.1.4 스파크"></a>1.1.4 스파크</h4><h5 id="하둡이란"><a href="#하둡이란" class="headerlink" title="하둡이란"></a>하둡이란</h5><p>빅데이터라는 용어가 이렇게 대중적으로 알려지게 된 데는 하둡의 탄생과 성공이 크게 기여했습니다. 하둡은 구글이 대용량 처리와 관련해서 공개한 두 개의 논문을 Doug Cutting 이 실제 제품으로 구현하면서 시작된 아파치 프로젝트를 가리키는 이름입니다.<br>하둡은 여러 대의 서버를 이용해서 하나의 클러스터를 구성하며, 이렇게 클러스터로 묶인 서버의 자원을 하나의 서버처럼 사용할 수 있는 클러스터 컴퓨팅 환경을 제공합니다. 기본 동작 방법은 <strong>분석할 데이터를 하둡 파일 시스템인 HDFS 에 저장해 두고, HDFS 상에서 Map Reduce 프로그램을 이용해 데이터 처리를 수행하는 방식</strong>입니다.<br>데이터를 저장할 때는 전체 데이터를 ‘블록’ 이라고 하는 일정한 크기로 나눠서 여러 데이터 노드에 분산해서 저장합니다. 이 때, 각 블록들이 어느 데이터 노드에 저장돼 있는지에 대한 메타정보를 네임 노드에 기록합니다. 그리고 맵 리듀스 작업을 실행할때는 네임노드로부터 메타정보를 읽어서 처리할 데이터의 위치를 확인하고 분산 처리를 수행합니다.</p></div><a class="article-more button is-small is-size-7" href="/2019/06/23/spark-intro/#more">Read more</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><p class="title is-size-4 is-block" style="line-height:inherit;">Junhee Ko</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">310</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/junhee-ko" target="_blank" rel="noopener">Follow</a></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-31T15:00:00.000Z">2021-08-01</time></p><p class="title"><a href="/2021/08/01/kotlin-basic/">코틀린 기초</a></p><p class="categories"><a href="/categories/kotlin/">Kotlin</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-31T15:00:00.000Z">2021-08-01</time></p><p class="title"><a href="/2021/08/01/kotlin-function/">함수 정의와 호출</a></p><p class="categories"><a href="/categories/kotlin/">Kotlin</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-24T15:00:00.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/spring-data-jpa-crud/">Spring Data JPA CRUD</a></p><p class="categories"><a href="/categories/jpa/">JPA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-21T15:00:00.000Z">2021-04-22</time></p><p class="title"><a href="/2021/04/22/ack-mode-batch/">Spring Kafka Listener Container BATCH AckMode</a></p><p class="categories"><a href="/categories/kafka/">Kafka</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-20T15:00:00.000Z">2021-04-21</time></p><p class="title"><a href="/2021/04/21/cmak/">CMAK</a></p><p class="categories"><a href="/categories/kafka/">Kafka</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">180</span></span></a></li><li><a class="level is-mobile" href="/categories/big-data/"><span class="level-start"><span class="level-item">Big Data</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/container/"><span class="level-start"><span class="level-item">Container</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/jpa/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/kafka/"><span class="level-start"><span class="level-item">Kafka</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/kotlin/"><span class="level-start"><span class="level-item">Kotlin</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/oauth/"><span class="level-start"><span class="level-item">OAuth</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/oop/"><span class="level-start"><span class="level-item">OOP</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/os/"><span class="level-start"><span class="level-item">OS</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/redis/"><span class="level-start"><span class="level-item">Redis</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/tdd/"><span class="level-start"><span class="level-item">TDD</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile" href="/categories/test-code/"><span class="level-start"><span class="level-item">Test Code</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/grpc/"><span class="level-start"><span class="level-item">gRPC</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a><p class="is-size-7"><span>&copy; 2021 junhee.ko</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>